\section{Parameters optimization}
\label{sec:methodologies-parameters-optimization}

We used an end-to-end learning mechanism to find the set of model parameters that produced the best fitting curves to the ground truth data.
In the model learning period, we only had access to observations for some of the compartments in the model because of the availability of data.
With county-level data and province-level data, we did not have access to the states $\{S, E, I, R\}$ but only the $D$ and $C$ states, which were the number of total deaths and the number of total confirmed cases.
With country-level data, we did not have access to the states $\{S, E\}$ but only the $I$, $R$, $D$, and $C$ states, which were the number of infective individuals, the number of total recoveries, the number of total deaths, and the number of total confirmed cases.
Therefore, the model could only learn from partially-available observations where the available data for some compartments were used to supervise the learning process while other compartments were left unconstrained.

All versions of the model were trained by minimizing the following loss function
\begin{equation}
    \mathcal{L}(\hat{y}, y) = \sum_{i=1}^N \sum_{t=0}^{T-1} e^{t\zeta} (log(\hat{y}_{i,t} + 1) - log(y_{i,t} + 1))^2.
    \label{eq:ude-model-loss}
\end{equation}
$N$ is the number of compartments that are observable, $T$ is the number of collocation points, i.e., the number of days that were used for training, and $e^{t\zeta}$ is a weighting factor that places higher priority to later data points.
$\zeta$ is a hyperparameter that can be chosen when we train the model to control how fast we want to weighting factor to grow with respect to time.
Lastly, $\hat{y}_{t,t}$ is the model's output for compartment $i$ at time $t$, and $y_{i,t}$ is the observation for compartment $i$ at time $t$.
The errors between the ground truth data and our model's predictions were taken in logarithmic scale, $log(\hat{y}_{i,t} + 1) - log(y_{i,t} + 1)$, because the states of the system were in vastly different scales.
Here, the number of totals confirmed cases were much larger than the number of deaths or the number of recoveries, which dominated the loss value and made the model learn poorly.
Before taking the log, we added $1$ to the values to take into account when the ground truth values or the predicted values were $0$.

We used a numerical \gls{ODE} solver that implemented the Tsitouras 5/4 Runge-Kutta method \cite{tsitourasRungeKuttaPairs2011} to solve our model's system of \glspl{ODE} on a given training time span.
In our problem, the model's outputs are the states of the system of \glspl{ODE} at each time step where the time steps correspond to the dates that were considered.
Once we obtained the model's outputs, minimization of the loss function in \autoref{eq:ude-model-loss} was carried out using adjoint sensitivity analysis \cite{maComparisonAutomaticDifferentiation2021} with the approach described by \citeauthor{rackauckasUniversalDifferentialEquations2020} \cite{rackauckasUniversalDifferentialEquations2020}.

The minimization process happened in 2 stages.
First, we used the ADAM optimizer \cite{kingmaAdamMethodStochastic2017} for some iterations and obtained the minimizing parameters found by it.
Once the ADAM optimizer finished, we performed a second stage of minimization using the BFGS optimizer \cite{broydenConvergenceClassDoublerank1970, fletcherNewApproachVariable1970, goldfarbFamilyVariablemetricMethods1970, shannoConditioningQuasiNewtonMethods1970} with the parameters that we obtained the ADAM optimizer.
\autoref{alg:seir-ude-training} presents the general procedure that was carried out in the 2 stages optimization process.
The strategy for using two stages of training had been proven to produce better output for \gls{UDE} problem \cite{rackauckasUniversalDifferentialEquations2020}.
After the first training stage with the ADAM optimizer, the parameters were put in a more reasonable parameters space.
Then in the second training stage, the BFGS optimizer would converge much quicker than when we used each of the optimizers on its own.

\begin{algorithm}
    \caption{General training procedure for the proposed models.}
    \label{alg:seir-ude-training}
    \begin{algorithmic}
        \State $y \gets \text{observations}$
        \Comment{Get the available observations of the compartments}

        \State $\theta \gets \text{random values}$
        \Comment{Randomly initialized the ANN's parameters}
        \State $p \gets \{ \gamma, \lambda, \alpha, \theta \}$
        \Comment{Set the initial values for the parameters that will be optimized}
        \State $u0 \gets \{ S_0, E_0, I_0, R_0, D_0, C_0, N_0 \}$
        \Comment{Set the system's initial conditions based on $y$}

        \State $\text{maxiters}_\text{ADAM} \gets \text{arbitrary integer}$
        \Comment{Set the maximum number of iterations for ADAM}
        \State $\text{maxiters}_\text{BFGS} \gets \text{arbitrary integer}$
        \Comment{Set the maximum number of iterations for BFGS}

        \State $i \gets 0$
        \Comment{Reset the iterations count to 0}
        \While{$i < \text{maxiters}_\text{ADAM}$}
            \State $\hat{y} \gets \text{ODESolver}(u_0, p)$
            \Comment{Solve the system with the time steps matching $y$}

            \State $p \gets p - ADAM(\Delta_p \mathcal{L}(\hat{y}, y))$
            \Comment{Update the parameters with the loss gradients}

            \If{$\mathcal{L}(\hat{y}, y) < \mathcal{L}_\text{min}$}
                \State $p_\text{min} \gets p$
                \Comment{Update the current minizing parameters}
                \State $\mathcal{L}_\text{min} \gets \mathcal{L}$
                \Comment{Update the current smallest loss value}
            \EndIf

            \State $i \gets i + 1$
            \Comment{Increment the iterations count}
        \EndWhile

        \State $i \gets 0$
        \Comment{Reset the iterations count to 0}
        \While{$i < \text{maxiters}_\text{BFGS}$ and not converge}
            \State $\hat{y} \gets \text{ODESolver}(u_0, p)$
            \Comment{Solve the system with the time steps matching $y$}

            \State $p \gets p - BFGS(\Delta_p \mathcal{L}(\hat{y}, y))$
            \Comment{Update the parameters with the loss gradients}

            \If{$\mathcal{L}(\hat{y}, y) < \mathcal{L}_\text{min}$}
                \State $p_\text{min} \gets p$
                \Comment{Update the current minizing parameters}
                \State $\mathcal{L}_\text{min} \gets \mathcal{L}$
                \Comment{Update the current smallest loss value}
            \EndIf

            \State $i \gets i + 1$
            \Comment{Increment the iterations count}
        \EndWhile
    \end{algorithmic}
\end{algorithm}