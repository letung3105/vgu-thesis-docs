\section{Parameters optimization}
\label{sec:methodologies-parameters-optimization}

An end-to-end learning mechanism was used to find the set of model parameters that produced the best fitting curves to the ground truth data.
In the model learning period, only the observations for some of the compartments in the model were accessible because of the availability of data.
With county-level data and province-level data, there was no observation for the states $\{S, E, I, R\}$ but only the $D$ and $C$ states, which were the number of total deaths and the number of total confirmed cases.
With country-level data, there was no observation for the states $\{S, E\}$ but only the $I$, $R$, $D$, and $C$ states, which were the number of infective individuals, the number of total recoveries, the number of total deaths, and the number of total confirmed cases.
Therefore, the model could only learn from partially-available observations where the available data for some compartments were used to supervise the learning process while other compartments were left unconstrained.

All versions of the model were trained by minimizing the following loss function
\begin{equation}
    \mathcal{L}(\hat{y}, y) = \sum_{i=1}^N \sum_{t=0}^{T-1} e^{t\zeta} (log(\hat{y}_{i,t} + 1) - log(y_{i,t} + 1))^2.
    \label{eq:ude-model-loss}
\end{equation}
$N$ is the number of compartments that are observable, $T$ is the number of collocation points, i.e., the number of days that were used for training, and $e^{t\zeta}$ is a weighting factor that places higher priority to later data points.
$\zeta$ is a hyperparameter that can be chosen when the model was trained to control how fast the weighting factor could grow with respect to time.
Lastly, $\hat{y}_{t,t}$ is the model's output for compartment $i$ at time $t$, and $y_{i,t}$ is the observation for compartment $i$ at time $t$.
The errors between the ground truth data and the model's predictions were taken in logarithmic scale, $log(\hat{y}_{i,t} + 1) - log(y_{i,t} + 1)$, because the states of the system were in vastly different scales.
Here, the number of totals confirmed cases were much larger than the number of deaths or the number of recoveries, which dominated the loss value and made the model learn poorly.
Before taking the log, $1$ is added to the values to take into account when the ground truth values or the predicted values were $0$.

A numerical \gls{ODE} solver that implemented the Tsitouras 5/4 Runge-Kutta method \cite{tsitourasRungeKuttaPairs2011} was used to solve the model's system of \glspl{ODE} on a given training time span.
In the problem, the model's outputs are the states of the system of \glspl{ODE} at each time step where the time steps correspond to the dates that were considered.
Once the model's outputs are obtained, minimization of the loss function in \autoref{eq:ude-model-loss} was carried out using adjoint sensitivity analysis \cite{maComparisonAutomaticDifferentiation2021} with the approach described by \citeauthor{rackauckasUniversalDifferentialEquations2020} \cite{rackauckasUniversalDifferentialEquations2020}.

The minimization process happened in 2 stages.
First, the ADAM optimizer \cite{kingmaAdamMethodStochastic2017} is used for some iterations, and the minimizing parameters found by it were obtained.
Once the ADAM optimizer finished, a second stage of minimization was performed using the BFGS optimizer \cite{broydenConvergenceClassDoublerank1970, fletcherNewApproachVariable1970, goldfarbFamilyVariablemetricMethods1970, shannoConditioningQuasiNewtonMethods1970} with the parameters that were obtained the ADAM optimizer.
\autoref{alg:seir-ude-training} presents the general procedure that was carried out in the 2 stages optimization process.
The strategy for using two stages of training had been proven to produce better output for \gls{UDE} problem \cite{rackauckasUniversalDifferentialEquations2020}.
After the first training stage with the ADAM optimizer, the parameters were put in a more reasonable parameters space.
Then in the second training stage, the BFGS optimizer would converge much quicker than when each of the optimizers was used on its own.

\begin{algorithm}
    \caption{General training procedure for the proposed models.}
    \label{alg:seir-ude-training}
    \begin{algorithmic}
        \State $y \gets \text{observations}$
        \Comment{Get the available observations of the compartments}

        \State $\theta \gets \text{random values}$
        \Comment{Randomly initialized the ANN's parameters}
        \State $p \gets \{ \gamma, \lambda, \alpha, \theta \}$
        \Comment{Set the initial values for the parameters that will be optimized}
        \State $u0 \gets \{ S_0, E_0, I_0, R_0, D_0, C_0, N_0 \}$
        \Comment{Set the system's initial conditions based on $y$}

        \State $\text{maxiters}_\text{ADAM} \gets \text{arbitrary integer}$
        \Comment{Set the maximum number of iterations for ADAM}
        \State $\text{maxiters}_\text{BFGS} \gets \text{arbitrary integer}$
        \Comment{Set the maximum number of iterations for BFGS}

        \State $i \gets 0$
        \Comment{Reset the iterations count to 0}
        \While{$i < \text{maxiters}_\text{ADAM}$}
            \State $\hat{y} \gets \text{ODESolver}(u_0, p)$
            \Comment{Solve the system with the time steps matching $y$}

            \State $p \gets p - ADAM(\Delta_p \mathcal{L}(\hat{y}, y))$
            \Comment{Update the parameters with the loss gradients}

            \If{$\mathcal{L}(\hat{y}, y) < \mathcal{L}_\text{min}$}
                \State $p_\text{min} \gets p$
                \Comment{Update the current minizing parameters}
                \State $\mathcal{L}_\text{min} \gets \mathcal{L}$
                \Comment{Update the current smallest loss value}
            \EndIf

            \State $i \gets i + 1$
            \Comment{Increment the iterations count}
        \EndWhile

        \State $i \gets 0$
        \Comment{Reset the iterations count to 0}
        \While{$i < \text{maxiters}_\text{BFGS}$ and not converge}
            \State $\hat{y} \gets \text{ODESolver}(u_0, p)$
            \Comment{Solve the system with the time steps matching $y$}

            \State $p \gets p - BFGS(\Delta_p \mathcal{L}(\hat{y}, y))$
            \Comment{Update the parameters with the loss gradients}

            \If{$\mathcal{L}(\hat{y}, y) < \mathcal{L}_\text{min}$}
                \State $p_\text{min} \gets p$
                \Comment{Update the current minizing parameters}
                \State $\mathcal{L}_\text{min} \gets \mathcal{L}$
                \Comment{Update the current smallest loss value}
            \EndIf

            \State $i \gets i + 1$
            \Comment{Increment the iterations count}
        \EndWhile
    \end{algorithmic}
\end{algorithm}