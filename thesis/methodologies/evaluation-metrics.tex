\section{Evaluation metrics}
\label{sec:methodologies-evaluation-metrics}

We compared out of sample performance of the models using various metrics which include \gls{MAPE}, \gls{MAE}, and \gls{RMSE}. For $n$ observations, given the predictions $\hat{y}_i$ and the ground truth $y_i$, the definitions of these evaluation metrics are given as
\begin{align*}
    MAE &= \frac{1}{n} \sum_{i=1}^n \left| \hat{y}_i - y_i \right| \\
    MAPE &= \frac{100}{n} \sum_{i=1}^n \left| \frac{\hat{y}_i - y_i}{y_i} \right| \\
    RMSE &= \sqrt{\frac{1}{n} \sum_{i=1}{n} (\hat{y}_i - y_i)^2}
\end{align*}
These three metrics are commonly used for evaluating the quality of regression models.
Multiple different metrics were considered because each has its advantages and disadvantages when use for evaluation.
With \gls{MAE} and \gls{MAPE}, the final error increases linearly with the observation errors, and therefore, they are not sensitive to outliers.
The value calculated using \gls{MAE} is in the same unit as the data that was used as input, this makes it easier to understand and compare against other models.
\gls{MAPE} calculates to error in term of percentage so the final value does not depend on the unit of the input data, this makes it useful when compare different models that operate on different units of data.
One downside of \gls{MAPE} is that its value is infinite or undefined when the ground truth observation is close to zero or zero itself.
Thus this should not be applied when the observed values are zero at some time steps.
Unlike \gls{MAE} and \gls{MAPE}, \gls{RMSE} places more emphasis on larger observation error, as a result, the metric is more sensitive to outliers.
The value given by \gls{RMSE} is also in the same unit as the input data similar to \gls{MAE}.
Furthermore, we noted that these metrics had also been used by other researchers to evaluate their models \cite{rayEnsembleForecastsCoronavirus2020, ihmecovid-19forecastingteamModelingCOVID19Scenarios2021,arikInterpretableSequenceLearning}.
Hence, this gave us more insights into the performance of our model when compared against existing results that were applied to other countries and regions.
